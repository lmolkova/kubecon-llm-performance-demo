kind: HorizontalPodAutoscaler
apiVersion: autoscaling/v2
metadata:
  name: vllm
spec:
  scaleTargetRef:
    # point the HPA at the sample application
    # you created above
    apiVersion: apps/v1
    kind: Deployment
    name: vllm-deployment
  # autoscale between 1 and 10 replicas
  minReplicas: 1
  maxReplicas: 2
  metrics:
  # use a "Pods" metric, which takes the average of the
  # given metric across all pods controlled by the autoscaling target
  - type: Pods
    pods:
      # use the metric that you used above: pods/http_requests
      metric:
        name: vllm_gpu_cache_usage_perc
      target:
        type: Value
        averageValue: 0.05 # temporary threshold to trigger scaling faster